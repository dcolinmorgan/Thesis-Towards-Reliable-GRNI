% Thesis summary -------------------------------------

% Should be in swedish if thesis are in another language, otherwize in english.
\selectlanguage{swedish}

%\summarytitle{Summering}

%\begin{summary}        %this creates the heading for the declaration page
\chapter{Sammanfattning}
translate via
\r{a} \"a \"o \\

Order seems to have repeatedly arisen in the universe from an initial non-uniformly disordered state by way of fundamental laws.% The law of entropy seems to be at odds with what these fundamental laws have birthed, not of their own accord but as the byproduct of their action playing on an imbalance of initial subtypes of matter.
Where entropy would have preferred the void to stay uniformly empty, bodies began coalescing on ever greater scales, bringing more order to the disarray.% This order begot environments which bore heavier higher order elements.
As ever heavier elements began to permeate the void, momentary stability has been born quite opposing entropy's ultimate goal, scattering densities of matter here and there. As time has run, order begot ever greater order, until the greatest known feat of entropy destruction was born, life! (Or at least it would seem that way from its initial onset; recently it has been argued that life increases the overall entropy quicker than its absence \citep{england2013statistical}.) Since the emergence of replicating and self-replicating biomolecules, the number of intertwining relationships have shot up incredibly, with every new adaptation carrying with it novel uses for new and old components living and nonliving alike  (ie competition, symbiosis, parasitism, etc.). These relationships exist on near every scale of life, from zooplankton's reliance on tides brought by the moon to our societal reliance on ancient stores of carbon based energies; again, nothing in nature exists in a vacuum.

Such relationships can be mapped, cataloged and analyzed using networks. A network allows the flexibility of robust systems to be captured in a single structure; this is not to say networks force simplify; in fact many networks are so dense with connections they themselves defy interpretation much like the systems they detail \citep{dianati2016unwinding}. Any system containing two components can be summarized as a network, with each component shown as a node and their relationship to one another a link. Different weights and artistic embellishments can be ascribed to both node and link to increase the overall density of information, but it is really the model of the system as a whole which imbues meaning to any network. For example, when all links are accounted for you can glimpse the social impact of any news story, how wealth disseminates between families of a developing country, and of special focus here, how genes carry out the instructions encoded in our life code. What happens when one route of calling for a certain gene's activity is reduced-- is there another way it will be carried out or is the system irrevocably altered, doomed to adapt in another way or will it simply cease functioning at all. And when combinations of such pathways are altered, how have its ''survival instincts'' prepared it? Biological systems of all scales have been shown to be highly robust, as one may intuit from the array of human diets or the wealth of human, animal and other languages on this planet. Gene regulatory networks (GRN) are no exception. In fact, measuring any gene's relationship to another, ie inferring its local network, is exceedingly difficult for this very reason, that relationships span many intermediate players and are often compounded through unique loop structure reinforcing this relationship.

The GeneSPIDER toolbox in \textbf{Paper I} attempts to bring some constancy to this endeavor, providing equal footing to test many different methods of network inference, in the hope of maximizing reliability. The environment enables synthetic data creation mirroring many properties of real biological, experimentally derived data; this data enables full control, something quite lacking in true investigation and allows for estimations of accuracy. Modern methods of network inference vary in many regards, none less trivial than their appropriation of variation among measurements. Our framework for FDR control in network inference in \textbf{Paper II} samples this variation in frequencies enough to provide the underlying inference model with a reasonable approximation of the variability inherent to the system, returning a reliable network based on a fairly strict criteria for accepting false links in the network. The perturbation-based inference present in the \textbf{Paper III} study is the culmination of these and other studies, all of which guided primary experimental design, namely the inclusion of many replicates of individual perturbation. This data was then run under the FDR restricting framework to return a reliable network measured against a strict cross validation method. Similarly, using data properties to constrain inference to only that which is capable of being deciphered with reasonable accuracies among the noise (textbf{Paper IV}) may lead to better adoption in the field and thus less resistance when entering the clinical domain; while removing much experimental data will undoubtedly frustrate, it could also spur the revolution for greater experimental depth in biological characterization.% lessons learned were used on a larger scale in the larger scale network inference of \textbf{Paper IV} to test our theory on larger datasets where biomedical relevance is much more apparent.
\\






%\end{summary}

\selectlanguage{english}

% ----------------------------------------------------------------------