% Thesis Abstract -----------------------------------------------------

\begin{abstracts}

Phenotypic traits are now known to stem from the interplay between genetic variables across many if not every level of biology. The field of gene regulatory network (GRN) inference is concerned with understanding the regulatory interactions between genes in a cell, in order to build a model that captures the behaviour of the system. Perturbation biology, whereby genes or RNAs are targeted and their activity altered, is of great value for the GRN field. By first systematically perturbing the system and then reading the system's reaction as a whole, we can feed this data into various methods to reverse engineer the key agents of change. 

The initial study sets the groundwork for the rest, and deals with finding common ground among the sundry methods in order to compare and rank performance in an unbiased setting. The GeneSPIDER (GS) MATLAB package is an inference benchmarking platform whereby methods can be added via a wrapper for testing in competition with one another. Synthetic datasets and networks spanning a wide range of conditions can be created for this purpose. The evaluation of methods across various conditions in the benchmark therein demonstrates which properties influence the accuracy of which methods, and thus which are more suitable for use under given characterized condition.

The second study introduces a novel framework NestBoot for increasing inference accuracy within the GS environment by independent, nested bootstraps, \ie repeated inference trials. Under low to medium noise levels, this allows support to be gathered for links occurring most often while spurious links are discarded through comparison to an estimated null distribution of shuffled-links. While noise continues to plague every method, nested bootstrapping in this way is shown to increase the accuracy of several different methods.

The third study applies NestBoot on real data to infer a reliable GRN from an small interfering RNA (siRNA) perturbation dataset covering 40 genes known or suspected to have a role in human cancers. Methods were developed to benchmark the accuracy of an inferred GRN in the absence of a true known GRN, by assessing how well it fits the data compared to a null model of shuffled topologies. A network of high confidence was recovered containing many regulatory links known in the literature, as well as a slew of novel links.

The fourth study seeks to infer reliable networks on large scale, utilizing the high dimensional biological datasets of the LINCS L1000 project.  This dataset has too much noise for accurate GRN inference as a whole, hence we developed a method to select a  subset that is sufficiently informative to accurately infer GRNs. This is a first step in the direction of identifying probable submodules within a greater genome-scale GRN yet to be uncovered.

%eek to firstly isolate signal amongst noise. We hope to demonstrate some semblance of a core network module necessary for disease development through quite a basic relatedness comparison but over large enough a scale to bring about insight into novel mechanisms of cancer progression.

%The contributions I have made to the field are: 1) the creation of GeneSPIDER an environment for comparing inference methods; 2) NestBoot, a framework for enhancing many inference methods’ accuracy; 3) BalanceFitError (BFE), a method for measuring accuracy of inferred networks when gold standards are unavailable. GeneSPIDER has developed into the benchmarking environment for the consequent two projects. The NestBoot method initially found only a marginal ability to increase inference accuracies by comparing the network overlap across bootstraps. It was redesigned to implement a more strict thresholding manner by forming a null network distribution from the inference of networks based upon shuffled data, lending to the ability of the NestBoot framework to infer accurate networks by defining a way to enforce a naive but conservative FDR threshold. Similarly, BFE aims to overcome the limitation of scoring inference accuracy when no gold standard network is available by developing another null. Unlike our NestBoot null, here GRN links are shuffled after the initial inference to form a null expected-link distribution by which to compare any inferred network’s link composition, allowing us to score the ability of an inferred network to explain data relative to an expected error defined by this null distribution.
% In what I see as the culmination of my PhD studies,  spearheaded a fourth study, which leverages experimental replicates within a high dimensionality public dataset. 
%All things must pass, and while I could never have imagined such a productive and exciting period of my life, it is with great excitment that I move on to the next adventure with Stockholm forever in my heart.


\end{abstracts}

% ---------------------------------------------------------------------- 
